---
title: "ST558_2024_HW8_bike data"
format: html
editor: visual
---

# Basic Modeling Practise

## Data introduction

Today we are using a bike share data for the basic modeling practise. The introoduction of this data set is accessed through this website: (Seoul Bike Sharing Demand - UCI Machine Learning Repository). To our relieve there is no missing values.

The aim of the project is to predict the rental bike count at each hour of a day based on the weather condition, season, holiday and the hour. Since bike usage is sensitive to weather condition it is presumable that certain weather condition, plus the day condition (weekday/weekend, holiday, etc.) is likely to dictate the bike usage in a particular time of the day.

Let's load some packages and read in the data first:

```{r}
library (tidyverse)
library (dplyr)
Bikeshare <- read_csv ("data//SeoulBikeData.csv")
Bikeshare

```

Unexpectedly the first trial to read in data failed. It turned out the file contains some special character that the R does not understand/not encoded by the R-recognizable way.

## Data Cleaning

After changing the format manually everything is fine. We first transform the date to the date format

```{r}
Bikeshare$Date <- as.Date (Bikeshare$Date, format = "%d/%m/%Y")
```

Now the date are in the right form and can do some visualization around the time data, which we will work on that later. Missing values are creating a headache for exploratory data analysis, so we want to check for missingness, evaluate and take measures to eliminate the missing values.

```{r}
colSums(is.na(Bikeshare))
length(unique(Bikeshare$Seasons))
```

Luckily for us, there is no missing data in the data set. To check for the number of unique values in each character column, use the command table(), and if everything is right turn the character variables into factors.

```{r}
table(Bikeshare$Seasons)
table (Bikeshare$Holiday)
table (Bikeshare$`Functioning Day`)
Bikeshare <- Bikeshare |> mutate (SeasonsF = as.factor (Seasons),
                                  HolidayF = as.factor (Holiday)) |>
  filter (`Functioning Day` == "Yes") |>
  select (-Seasons, -Holiday, -`Functioning Day`)
```

We filtered the data so that all days recorded were "functional day" and factorized variables "Seasons" and "Holiday". Since we wanted to summarize across the hours to simplify the data (thus eliminating the need to adjust for the hour variable), we will hereby factorize date as well.

```{r}
Bikeshare <- Bikeshare |> mutate (DateF = as.factor (Date))
```

Now we are ready to do some EDA.

## Exploratory data analysis

Let's first do summary over some variables. We already counted the number of each unique factors of the categorical variables, we could summarize them as below. First let's take a look at the variables of the modified data set

```{r}
str (Bikeshare)
```

For the variable "Rented Bike Count", "Rainfall (mm)", "Snowfall (cm)", we would like to get summary data based on the **summed** value in a day (added up all the hour data). For other weather-related data, we would like to get a summary of the **mean** across all the hours in a day.

```{r}
rentalcount_precipitation_summary <-Bikeshare |> group_by(Date) |>
  summarize (across(c(`Rented Bike Count`,`Rainfall(mm)`,`Snowfall (cm)`),
             .fns = list ("Daily" = sum)))
summary(rentalcount_precipitation_summary)

weather_summary <- Bikeshare |> group_by(Date) |>
  summarize (across (c(`Temperature(C)`, `Humidity(%)`,`Wind speed (m/s)`,`Visibility (10m)`,`Dew point temperature(C)`,`Solar Radiation (MJ/m2)`),
                     .fns = list ("Daily" = mean)))
summary (weather_summary)

```

We could combine the two data set into one.

```{r}
Bikesharenew <- left_join(rentalcount_precipitation_summary,
                          weather_summary)
str(Bikesharenew)
```

Based on the merged data set, we will do more work â€“ To better visualize the distribution of variables, histogram seemed to be the choice.

```{r}
library (gridExtra)
rentalcount <- ggplot (Bikesharenew, aes (x = `Rented Bike Count_Daily`)) +
  geom_histogram(color = "black", fill = "red3", alpha = 0.5) +
  labs (x = "Daily rented Bike Count")

rainfall <- ggplot (Bikesharenew, aes (x = `Rainfall(mm)_Daily`)) +
  geom_histogram(color = "black", fill = "lightgreen", alpha = 0.5) +
  labs (x = "Daily rainfall (mm)")

snowfall <- ggplot (Bikesharenew, aes (x = Bikesharenew$`Snowfall (cm)_Daily`)) +
  geom_histogram(color = "brown", fill = "white", alpha = 0.5) +
  labs (x = "Daily snowfall (cm)")

Temperature <- ggplot (Bikesharenew, aes (x = Bikesharenew$`Temperature(C)_Daily`)) +
  geom_histogram(color = "black", fill = "orange", alpha = 0.5) +
  labs (x = "Daily avg Temp (oC)")

Humidity <- ggplot (Bikesharenew, aes (x = Bikesharenew$`Humidity(%)_Daily`)) +
  geom_histogram(color = "black", fill = "lightblue", alpha = 0.5) +
  labs (x = "Daily avg Humidity (%)")

windspeed <- ggplot (Bikesharenew, aes (x = Bikesharenew$`Wind speed (m/s)_Daily`)) +
  geom_histogram(color = "lightblue4", fill = "pink", alpha = 0.5) +
  labs (x = "Daily avg windspeed (m/s)")

visibility <- ggplot (Bikesharenew, aes (x = Bikesharenew$`Visibility (10m)_Daily`)) +
  geom_histogram(color = "lightblue", fill = "white", alpha = 0.5) +
  labs (x = "Daily avg Visibility (10m)")

dewpoint <- ggplot (Bikesharenew, aes (x = Bikesharenew$`Dew point temperature(C)_Daily`)) +
  geom_histogram(color = "green", fill = "ivory", alpha = 0.5) +
  labs (x = "Daily avg dew point temp (oC)")

solar <- ggplot (Bikesharenew, aes (x = Bikesharenew$`Solar Radiation (MJ/m2)_Daily`)) +
  geom_histogram(color = "red", fill = "orange2", alpha = 0.5) +
  labs (x = "Daily avg solar radiation (MJ/m2)")

grid.arrange(rentalcount,rainfall,snowfall,Temperature,Humidity,windspeed,visibility,dewpoint,solar, ncol = 3)
```

It is interesting to see the rough bi-modal distribution of rented bike count. neither **mean** nor **median** fall on either peak. Probably it is just good and bad weather conditions that is driving this division.

In order to assist data modeling, not only we are interested in which variable contributes the most to the changes of bike rental count, but also we wanted to figure out the correlation among different predictors. Thus we would use corr plot to visualize the relationship

```{r}
library (corrplot)
cor_matrix <- cor(Bikesharenew |> select (-Date))  # Compute correlation matrix
corrplot(cor_matrix, method = "circle", type = "upper", tl.cex = 0.8)
```

From this correlation plot it is easy to see the daily number of checked out bike is highly positively correlated with the daily temperature, dewpoint and solar radiation. However since both dewpoint and solar radiation are highly correlated with the temperature themselves, we will wait to see whether we should include them all. On the contrary, daily rainfall, snowfall or windspeed is negatively associated with bike count. But remember the distribution of those three variable is far from normal distribution, so maybe it would help to transform the three variables into categorical variables to better model the bike rental count.

## Split the data

Now we could model our data Bikesharenew. First let's split them using seasons to stratify. However we missed the categorical variables in the original data set. Let's fix this first!

```{r}
Bikeshare_cat <- Bikeshare |> select (Date, SeasonsF, HolidayF) |> unique()
str (Bikeshare_cat)
Bikesharenew2 <- left_join(Bikesharenew, Bikeshare_cat, by = join_by(Date))
str (Bikesharenew2)
```

Here we inspect the column names for the **Bikesharenew2** data frame and found they could prove to be problematic. Change them now.

```{r}
newnames <- c ("Rainfall_daily", "Snowfall_daily",
               "TempC_daily", "Humidity_daily",
               "Windspeed_daily", "Visibility_daily",
               "DewtempC_daily", "solarrad_daily")
colnames (Bikesharenew2) [3:10] <- newnames
str (Bikesharenew2)
```

Now it's all good and we could proceed with splitting the data.

```{r}
library (tidymodels)
Bikesharesplit <- initial_split (Bikesharenew2, prop = 0.75, strata = SeasonsF)
```

Now create a 10-fold CV on training set.

```{r}
bikesharetrain <- training (Bikesharesplit)
bikeshare_10_fold <- vfold_cv(bikesharetrain,10)
```

## MLR model fitting

Now let's create three different recipe, with the first recipe only considering simple linear regression model. Use the recipe () and bake () to see if it works.

```{r}
recipe (`Rented Bike Count_Daily` ~., data = bikesharetrain) |>
  step_date (Date, features = "dow") |>
  step_mutate (Date_dow = as.character(Date_dow)) |>
  step_mutate (Days = ifelse(Date_dow %in% c("Sat", "Sun"), "weekend", "weekday")) |>
  step_mutate (Days = factor (Days, levels = c ("weekend", "weekdays"))) |>
  step_normalize (all_numeric(),-all_outcomes()) |>
  step_unknown (Days, new_level = "unknown days") |>
  step_dummy (SeasonsF, HolidayF, Days) |>
  prep (training = bikesharetrain) |>
  bake (bikesharetrain)
```

Well, it seemed to work. Apply this to the first recipe.

```{r}
bikeshare_rec_1 <- recipe (`Rented Bike Count_Daily` ~., data = bikesharetrain) |>
  step_date (Date, features = "dow") |>
  step_mutate (Date_dow = as.character(Date_dow)) |>
  step_mutate (Days = ifelse(Date_dow %in% c("Sat", "Sun"), "weekend", "weekday")) |>
  step_mutate (Days = factor (Days, levels = c ("weekend", "weekdays"))) |>
  step_normalize (all_numeric(),-all_outcomes()) |>
  step_unknown (Days, new_level = "unknown days") |>
  step_dummy (SeasonsF, HolidayF, Days)
```

Let's create the 2nd recipe, adding several interactions while keeping most of the recipe unchanged.

```{r}
recipe (`Rented Bike Count_Daily` ~., data = bikesharetrain) |>
  step_date (Date, features = "dow") |>
  step_mutate (Date_dow = as.character(Date_dow)) |>
  step_mutate (Days = ifelse(Date_dow %in% c("Sat", "Sun"), "weekend", "weekday")) |>
  step_mutate (Days = factor (Days, levels = c ("weekend", "weekdays"))) |>
  step_normalize (all_numeric(),-all_outcomes()) |>
  step_unknown (Days, new_level = "unknown days") |>
  step_dummy (SeasonsF, HolidayF, Days) |>
  step_interact (terms = ~ starts_with ("Season") * HolidayF_No.Holiday + 
                          starts_with("Season") * TempC_daily +
                  TempC_daily * Rainfall_daily) |>
  prep (training = bikesharetrain) |>
  bake (bikesharetrain)
```

```{r}
bikeshare_rec_2 <- recipe (`Rented Bike Count_Daily` ~., data = bikesharetrain) |>
  step_date (Date, features = "dow") |>
  step_mutate (Date_dow = as.character(Date_dow)) |>
  step_mutate (Days = ifelse(Date_dow %in% c("Sat", "Sun"), "weekend", "weekday")) |>
  step_mutate (Days = factor (Days, levels = c ("weekend", "weekdays"))) |>
  step_normalize (all_numeric(),-all_outcomes()) |>
  step_unknown (Days, new_level = "unknown") |>
  step_dummy (SeasonsF, HolidayF, Days) |>
  step_interact (terms = ~ starts_with ("Season") * HolidayF_No.Holiday + 
                          starts_with("Season") * TempC_daily +
                  TempC_daily * Rainfall_daily)
```

Proceed to add the 3rd recipe

```{r}
bikeshare_rec_3 <- recipe (`Rented Bike Count_Daily` ~., data = bikesharetrain) |>
  step_date (Date, features = "dow") |>
  step_mutate (Date_dow = as.character(Date_dow)) |>
  step_mutate (Days = ifelse(Date_dow %in% c("Sat", "Sun"), "weekend", "weekday")) |>
  step_mutate (Days = factor (Days, levels = c ("weekend", "weekdays"))) |>
  step_normalize (all_numeric(),-all_outcomes()) |>
  step_unknown (Days, new_level = "unknown") |>
  step_dummy (SeasonsF, HolidayF, Days) |>
  step_interact (terms = ~ starts_with ("Season") * HolidayF_No.Holiday + 
                          starts_with("Season") * TempC_daily +
                  TempC_daily * Rainfall_daily) |>
  step_poly (Rainfall_daily, Snowfall_daily, Windspeed_daily, solarrad_daily)
  
```

There was an error saying the *degree* of the polynomial needs to be smaller than the unique number of a variable, but according to my observation all numeric variable has more than two unique values. This I do not understand, but I manually chose some anyway.

Now set up our linear model to the engine "lm"

```{r}
bikeshare_mod <- linear_reg() |> set_engine ("lm")
bikeshare_wfl_1 <- workflow() |> add_recipe (bikeshare_rec_1) |> add_model (bikeshare_mod)
bikeshare_wfl_2 <- workflow() |> add_recipe (bikeshare_rec_2) |> add_model (bikeshare_mod)
bikeshare_wfl_3 <- workflow() |> add_recipe (bikeshare_rec_3) |> add_model (bikeshare_mod)
```

Now we are using the CV data to fit the three different models.

```{r}
bikeshare_cv_fit_1 <- bikeshare_wfl_1 |> fit_resamples (bikeshare_10_fold)
bikeshare_cv_fit_2 <- bikeshare_wfl_2 |> fit_resamples (bikeshare_10_fold)
bikeshare_cv_fit_3 <- bikeshare_wfl_3 |> fit_resamples (bikeshare_10_fold)

rbind ((bikeshare_cv_fit_1 |> collect_metrics()),
(bikeshare_cv_fit_2 |> collect_metrics()),
(bikeshare_cv_fit_3 |> collect_metrics()))
```

Well, our data showed adding some interaction terms and polynomial terms indeed improved the model, as the mean RMSE reduced, but the value of RSQ did not reduce, meaning adding a lot of interaction term did not improve too much of our model. Now fit the third model into our entire training set.

```{r}
MLR_final <- bikeshare_wfl_3 |> fit (bikesharetrain)
tidy (MLR_final)
```

Judging from the p-value, the most significant beta is from the interaction between Season_Summer and TempC_daily, suggesting in summer days, increased temperature is likely to reduce the number of rented bike (Take note all numeric value were standardized here). Sundays are definitely unpopular days since being Sunday is predicted to reduce the number of rented bike by 3601 per day. As we may predict, summer days are much more popular than winter days to ride a bike, and rainfall is sure downpour people's enthusiasm to ride a bike as well.